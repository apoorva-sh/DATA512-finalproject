{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A7: Final Project Report\n",
    "\n",
    "### I. Introduction\n",
    "\n",
    "For years researchers have explored and tried to map the way we can tap into human emotional responses with simple environmental cues, such as the visual surroundings, auditory stimuli, sensory stimuli, etc. \n",
    "\n",
    "There has been significant research in the field of identifying sounds as purely belonging to a certain sound group (i.e. happy or sad) which has resulted in the creation of a corpus of melodies, created specifically as a building block to delve deeper into how human beings map emotions and music.\n",
    "\n",
    "Such studies help us further understand how our brains connect memories, emotions, and external stimuli together.\n",
    "\n",
    "This project tries to explore certain questions in the area of mapping musical stimuli with first emotional response, using data generated by a study conducted in Stockholm and Finland in 2013 titled: [Emotional expression in music: contribution, linearity, and additivity of primary musical cues](https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00487/full)\n",
    "\n",
    "The data is licensed under [CC0](https://creativecommons.org/publicdomain/zero/1.0/) (public use) and is hosted by [Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IFOBRN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Related work and Background\n",
    "\n",
    "The corpus of work that inspired this project is\n",
    "\n",
    "### a) [Happy, sad, scary and peaceful musical excerpts for research on emotions - Veillard et. al](https://www.researchgate.net/publication/247496910_Happy_sad_scary_and_peaceful_musical_excerpts_for_research_on_emotions)\n",
    "\n",
    "This body of work categorized 56 musical excerpts as Happy, Sad, Scary, and Peaceful on a continuous range (assigning a percentage wise score for each melody in each category)\n",
    "\n",
    "This work generated 4 key melodies that were classified as unambigously Sad, Scary, Happy, or Peaceful, and these melodies were used as the basis for the research that generated the data I have used in this project.\n",
    "\n",
    "This research was conducted with the key goal in mind of setting a stepping stone for further research in the area of emotion and melody mapping.\n",
    "\n",
    "This study cites several other papers that map emotion conveyed by a melody to be non-subjective, but rather very clearly common in musically educated and uneducated listeners ( [Bigand et al](http://leadserv.u-bourgogne.fr/files/publications/000103-multidimensional-scaling-of-emotional-responses-to-music-the-effect-of-musical-expertise-and-of-the-duration-of-the-excerpts.pdf) )\n",
    "\n",
    "The purpose of this study was not directed in the area of mapping emotional response to CHANGE in melody, but to see if listeners could map unlabelled music intended to convey a certain emotion as the same, and the found inherently that that was in fact the case. Happy and Sad music was easily identified as such by an overwhelming majority.\n",
    "\n",
    "\n",
    "### b) [Emotion rendering in music: range and characteristic values of seven musical variables](https://www.ncbi.nlm.nih.gov/pubmed/21696717)\n",
    "\n",
    "This body of work identifies the characteristics of music that actually affect the emotional response of a listener. As opposed to factorially altering all characteristics of music with arbitrary values, this research proposes that only certain values of certain characteristics actyally illicit an emotional response.\n",
    "\n",
    "This work is on the basis of which the data on the 200 melodic stimuli I have used in this project was designed. \n",
    "\n",
    "### c) [Emotional expression in music: contribution, linearity, and additivity of primary musical cues](https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00487/full)\n",
    "\n",
    "This body of work generated the data that I have used in this project. The researchers used previously identified unabiguously sad happy peaceful and scary melodies (Using Veillard et al. results) to generate 200 musical stimuli, by factorially changing key values as identified by Bresin et. al. The researchers then asked 46 test subjects to listen to this stimuli and rate each melody as Happy, Scary, Sad, and Peaceful on a scale of 1 to 7 (Thus each melody would have 4 ratings per user.)\n",
    "\n",
    "From this data the researchers identified the linearity of the relationship between emotional response and each characteristic, and tried to break down the dependency of each value and the emotional response.\n",
    "\n",
    "## III. Research Questions, Results, and Code\n",
    "\n",
    "The questions I wanted to focus on are a small subset of what Tuomas et al. tried to look into, I wanted to conduct some Exploratory Data Analysis to see how the relationship between certain characteristics of music aligned with my own understanding of music.\n",
    "\n",
    "### Setup\n",
    "\n",
    "First let us import the relevant packages and load the data:\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat = pd.read_csv('../Data/design_matrix.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_rating = pd.read_csv('../Data/mean_emotion_ratings.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Before we delve into the research questions, let's take a quick look at the data\n",
    "\n",
    "#### Design Matrix\n",
    "\n",
    "This table contains information on 200 melodic stimuli, with each row describing one melody.\n",
    "\n",
    "The columns contain the following encodings:\n",
    "\n",
    "- **Register** - 6 levels\n",
    "    - 1: 53 MIDI pitch\n",
    "    - 2: 59 MIDI pitch\n",
    "    - 3: 65 MIDI pitch\n",
    "    - 4: 71 MIDI pitch\n",
    "    - 5: 77 MIDI pitch\n",
    "    - 6: 83 MIDI pitch\n",
    "- **Mode** - 2 modes\n",
    "    - 1: Major key\n",
    "    - 2: Minor key\n",
    "- **Tempo** - 5 tempos (in NPS)\n",
    "    - 1: 1.2\n",
    "    - 2: 2\n",
    "    - 3: 2.8\n",
    "    - 4: 4.4\n",
    "    - 5: 6\n",
    "- **Sound level** - 5 sound levels (in dB)\n",
    "    - 1: -10\n",
    "    - 2: -5\n",
    "    - 3: 0\n",
    "    - 4: +5\n",
    "    - 5: +10\n",
    "- **Articulation** - 4 levels (from legato to staccato)\n",
    "- **Timbre** - 3 levels \n",
    "    - 1: trumpet\n",
    "    - 2: flute\n",
    "    - 3: horn\n",
    "- **Melody** - 4 types\n",
    "    - 1: Sad\n",
    "    - 2: Scary\n",
    "    - 3: Happy\n",
    "    - 4: Peaceful\n",
    "    \n",
    "\n",
    "Looking at the first five rows of the design_mat data we see how these encodings would look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Register</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Soundlevel</th>\n",
       "      <th>Articulation</th>\n",
       "      <th>Timbre</th>\n",
       "      <th>Melody</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nro</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Register  Mode  Tempo  Soundlevel  Articulation  Timbre  Melody\n",
       "Nro                                                                 \n",
       "1           4     1      4           4             2       2       4\n",
       "2           5     1      4           1             1       2       2\n",
       "3           2     2      5           1             1       2       1\n",
       "4           1     1      5           4             4       1       2\n",
       "5           3     2      1           3             2       2       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean emotional response\n",
    "\n",
    "This table contains the mean emotional response for 200 melodic stimuli, with each row co-inciding with one melody. This mean response has been calculated by averaging out the reaction of 46 users for each melody and each emotional category.\n",
    "\n",
    "Looking at the first five rows of the mean emotional response table, we can see what that would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scary</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Peaceful</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nro</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2889</td>\n",
       "      <td>4.4667</td>\n",
       "      <td>1.7111</td>\n",
       "      <td>3.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0667</td>\n",
       "      <td>5.4444</td>\n",
       "      <td>1.4889</td>\n",
       "      <td>4.4889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0222</td>\n",
       "      <td>1.4889</td>\n",
       "      <td>3.7778</td>\n",
       "      <td>2.7111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2889</td>\n",
       "      <td>4.1111</td>\n",
       "      <td>1.2667</td>\n",
       "      <td>1.4889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.4000</td>\n",
       "      <td>1.4667</td>\n",
       "      <td>5.0444</td>\n",
       "      <td>3.8444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Scary   Happy     Sad  Peaceful\n",
       "Nro                                  \n",
       "1    1.2889  4.4667  1.7111    3.1333\n",
       "2    1.0667  5.4444  1.4889    4.4889\n",
       "3    2.0222  1.4889  3.7778    2.7111\n",
       "4    2.2889  4.1111  1.2667    1.4889\n",
       "5    1.4000  1.4667  5.0444    3.8444"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 1: How linear is the relationship between \"Melody\" and \"Mean Emotional Response\"?\n",
    "\n",
    "    Since the melody is already classified in the same buckets as Mean Emotional Response, it would be interesting to know if the overreaching melody type has a predominant affect on the mean emotional response\n",
    "\n",
    "To analyze this, first for each melody I assigned a \"projected emotion\" value in the mean emotional response table. This value represented the max mean emotional response for each melody, and assigned the same encoding as that of \"Melody\" from teh design_mat table to the stimuli, 1: Sad, 2: Scary, 3: Happy, 4: Peaceful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "for i in emotion_rating.values:\n",
    "    if max(i) == i[0]:\n",
    "        a.append(2)\n",
    "    elif max(i) == i[1]:\n",
    "        a.append(3)\n",
    "    elif max(i) == i[2]:\n",
    "        a.append(1)\n",
    "    elif max(i) == i[3]:\n",
    "        a.append(4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_rating[\"projected emotion\"] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scary</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Peaceful</th>\n",
       "      <th>projected emotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nro</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2889</td>\n",
       "      <td>4.4667</td>\n",
       "      <td>1.7111</td>\n",
       "      <td>3.1333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0667</td>\n",
       "      <td>5.4444</td>\n",
       "      <td>1.4889</td>\n",
       "      <td>4.4889</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0222</td>\n",
       "      <td>1.4889</td>\n",
       "      <td>3.7778</td>\n",
       "      <td>2.7111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2889</td>\n",
       "      <td>4.1111</td>\n",
       "      <td>1.2667</td>\n",
       "      <td>1.4889</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.4000</td>\n",
       "      <td>1.4667</td>\n",
       "      <td>5.0444</td>\n",
       "      <td>3.8444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Scary   Happy     Sad  Peaceful  projected emotion\n",
       "Nro                                                     \n",
       "1    1.2889  4.4667  1.7111    3.1333                  3\n",
       "2    1.0667  5.4444  1.4889    4.4889                  3\n",
       "3    2.0222  1.4889  3.7778    2.7111                  1\n",
       "4    2.2889  4.1111  1.2667    1.4889                  3\n",
       "5    1.4000  1.4667  5.0444    3.8444                  1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we see that now each melody has a projected emotion. Now I calculated how many times this projected emotion matched the \"Melody\" encoding in the design_mat table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(design_mat)):\n",
    "    if design_mat.iloc[i,6] == emotion_rating.iloc[i,4]:\n",
    "               count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/len(design_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Thus 23% stimuli match projected emotion and actual theme of the melody\n",
    "\n",
    "This however still does not answer our question. To answer that we will plot the percentage wise matching of each stimuli's \"Melody\" and \"projected emotion\"\n",
    "\n",
    "First we will store a copy of the calculated \"projected emotion\" in the design_mat table as \"overall_emotion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat[\"overall_emotion\"] = emotion_rating[\"projected emotion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now calculate each emotion's match percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matching count for each Melody and overall_emotion\n",
    "mel1 = 0 \n",
    "mel2 = 0\n",
    "mel3 = 0\n",
    "mel4 = 0\n",
    "\n",
    "#Total count for each Melody\n",
    "tot1 = 0\n",
    "tot2 = 0\n",
    "tot3 = 0\n",
    "tot4 = 0\n",
    "\n",
    "for i in design_mat.values:\n",
    "    if i[6] == i[7]:\n",
    "        if i[6] == 1:\n",
    "            mel1 = mel1 + 1\n",
    "        elif i[6] == 2:\n",
    "            mel2 = mel2 + 1\n",
    "        elif i[6] == 3:\n",
    "            mel3 = mel3 + 1\n",
    "        elif i[6] == 4:\n",
    "            mel4 = mel4 + 1\n",
    "    \n",
    "    if i[6] == 1:\n",
    "        tot1 = tot1 +1\n",
    "    elif i[6] == 2:\n",
    "        tot2 = tot2 + 1\n",
    "    elif i[6] == 3:\n",
    "        tot3 = tot3 +1\n",
    "    else:\n",
    "        tot4 = tot4 + 1\n",
    "            \n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mel1p = mel1*100/tot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel2p = mel2*100/tot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mel3p = mel3*100/tot3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mel4p = mel4*100/tot4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store these values in a dataframe for ease of plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[[\"Sad\",mel1p],\n",
    "                       [\"Scary\",mel2p],\n",
    "                       [\"Happy\", mel3p],\n",
    "                       [\"Peaceful\",mel4p]], columns= [\"Melody Emotion\",\"Matching Percentage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(df, x='Melody Emotion', y='Matching Percentage')\n",
    "fig.update_traces(marker_color = \"purple\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting graph:\n",
    "\n",
    "<img src=\"RQ1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus we can see that Melody and overall_response do not match very much, thus the characteristics we have factorially altered does have some impact on mean emotional response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 2: Which factor most affects the relationship between \"Melody\" and \"Mean Emotional Response\"?\n",
    "\n",
    "    Which of the six musical factors most changes the mean emotional response from co-inciding with the Melody\n",
    "\n",
    "This should help us identify which factor most alters someone view on a melody. To calculate this we shall perform some simple linear regression and look at the intercept values to see which characteristic paired with melody reduces its impact on overall response\n",
    "\n",
    "Let us first see what the coefficient is for Linear regression of Mean emotional Response on Meldoy without any confounding variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeff:  [-0.01130298]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(design_mat.Melody).reshape((-1, 1))\n",
    "\n",
    "X.shape\n",
    "\n",
    "y = np.array(design_mat.overall_emotion)\n",
    "\n",
    "y.shape\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "print(\"coeff: \",model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient is -0.0113, now any characteristic that changes this value, making it closer to zero (Reducing its importance on the mean emotional response is the characteristic that most affects the relationship between melody and mean emotional response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Register</th>\n",
       "      <td>0.131411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melody</th>\n",
       "      <td>-0.012788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Coefficient\n",
       "Register     0.131411\n",
       "Melody      -0.012788"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = design_mat[['Register', 'Melody']].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=X,columns=[\"Register\",\"Melody\"])\n",
    "\n",
    "coeff_df = pd.DataFrame(model.coef_, df.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Timbre</th>\n",
       "      <td>0.007490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melody</th>\n",
       "      <td>-0.011272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient\n",
       "Timbre     0.007490\n",
       "Melody    -0.011272"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = design_mat[['Timbre', 'Melody']].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=X,columns=[\"Timbre\",\"Melody\"])\n",
    "\n",
    "coeff_df = pd.DataFrame(model.coef_, df.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Soundlevel</th>\n",
       "      <td>-0.061485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melody</th>\n",
       "      <td>-0.011290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficient\n",
       "Soundlevel    -0.061485\n",
       "Melody        -0.011290"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = design_mat[['Soundlevel', 'Melody']].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=X,columns=[\"Soundlevel\",\"Melody\"])\n",
    "\n",
    "coeff_df = pd.DataFrame(model.coef_, df.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Articulation</th>\n",
       "      <td>0.019712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melody</th>\n",
       "      <td>-0.012095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Coefficient\n",
       "Articulation     0.019712\n",
       "Melody          -0.012095"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = design_mat[['Articulation', 'Melody']].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=X,columns=[\"Articulation\",\"Melody\"])\n",
    "\n",
    "coeff_df = pd.DataFrame(model.coef_, df.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mode</th>\n",
       "      <td>-1.431565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melody</th>\n",
       "      <td>-0.011603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient\n",
       "Mode      -1.431565\n",
       "Melody    -0.011603"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = design_mat[['Mode', 'Melody']].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=X,columns=[\"Mode\",\"Melody\"])\n",
    "\n",
    "coeff_df = pd.DataFrame(model.coef_, df.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tempo</th>\n",
       "      <td>0.056447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melody</th>\n",
       "      <td>-0.009194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient\n",
       "Tempo      0.056447\n",
       "Melody    -0.009194"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = design_mat[['Tempo', 'Melody']].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=X,columns=[\"Tempo\",\"Melody\"])\n",
    "\n",
    "coeff_df = pd.DataFrame(model.coef_, df.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the above values, we can see that Tempo has the most effect on the relationship between Melody and Overall emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 3: Does a \"minor\" mode mostly illicit a \"Scary\" emotional response?\n",
    "\n",
    "    As a listener of music generally songs in a minor key can come off as creepy, I would like to know if that holds true for the populous\n",
    "\n",
    "\n",
    "For this analysis we will first find the subset of design_mat table that only contains Mode: 2 (Minor Key)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_key = design_mat[design_mat[\"Mode\"]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Register</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Soundlevel</th>\n",
       "      <th>Articulation</th>\n",
       "      <th>Timbre</th>\n",
       "      <th>Melody</th>\n",
       "      <th>overall_emotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nro</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Register  Mode  Tempo  Soundlevel  Articulation  Timbre  Melody  \\\n",
       "Nro                                                                    \n",
       "3           2     2      5           1             1       2       1   \n",
       "5           3     2      1           3             2       2       1   \n",
       "6           2     2      3           2             4       2       2   \n",
       "7           1     2      2           1             3       1       4   \n",
       "9           1     2      1           4             4       1       1   \n",
       "\n",
       "     overall_emotion  \n",
       "Nro                   \n",
       "3                  1  \n",
       "5                  1  \n",
       "6                  4  \n",
       "7                  1  \n",
       "9                  1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minor_key.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above table we see that only Mode 2 melodies are in this table, we shall remove the mode column now as it has no relevance for the rest of this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del minor_key[\"Mode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now calculate the percentage of each overall_emotion in the minor_key table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_sad = 0\n",
    "count_happy = 0\n",
    "count_peaceful = 0\n",
    "count_scary = 0\n",
    "\n",
    "for i in minor_key.values:\n",
    "    if i[6] == 1:\n",
    "        count_sad = count_sad + 1\n",
    "    elif i[6] == 2:\n",
    "        count_scary = count_scary + 1\n",
    "    elif i[6] == 3:\n",
    "        count_happy = count_happy + 1\n",
    "    elif i[6] == 4:\n",
    "        count_peaceful = count_peaceful + 1\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = [[\"Sad\", (count_sad*100)/len(minor_key)],\n",
    "                          [\"Happy\",(count_happy*100)/len(minor_key)],\n",
    "                          [\"Peaceful\",(count_peaceful*100)/len(minor_key)],\n",
    "                          [\"Scary\",(count_scary*100)/len(minor_key)]],\n",
    "                 columns = [\"Emotion\", \"%ge of minor key first response\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(df, x='Emotion', y='%ge of minor key first response')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting graph:\n",
    "\n",
    "<img src=\"RQ2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This shows that most minor key songs are categorized as sad, as opposed to scary. To dig deeper into this let us see how mean emotional response for scary maps to the \"Mode\" column of the design_mat (Which stores the key information for each stimuli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add a column to store the mean emotional response under \"Scary\" from the emotional_rating table to the design_mat table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat[\"average scary\"] = emotion_rating[\"Scary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(design_mat, x=\"average scary\", y=\"Mode\",\n",
    "\t         color = \"overall_emotion\", color_continuous_scale = \"RdBu\")\n",
    "fig.update_traces(mode='markers',  marker_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting graph:\n",
    "\n",
    "<img src=\"RQ3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus we see that as the Mode is set to 2 (Minor Key), the points are mostly warm colors (implying Sad or Scary) even if they are scored low on the average scary scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 4 : Does a high tempo lead to a happier emotional response?\n",
    "\n",
    "    Generally speaking fast tempo-ed songs (such as pop music) generate a positive response, it would be interesting to know if that is true here as well\n",
    "\n",
    "To analyze this we will follow a similar process, mapping Tempo against average_happy rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first get the average happy value into the design_mat table from emotional_rating table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat[\"average happy\"] = emotion_rating[\"Happy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add another dimension to our analysis, we shall count how many melodies have matching tempos and matching average rating (just to see if any one tempo has an overwhelmingly common average happy response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat[\"count\"] = 1 # Assign a count to each melody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now group by Tempo and average happy summing the count of each occurence \n",
    "anotherdf = pd.DataFrame(data = design_mat.groupby([\"Tempo\",\"average happy\"],as_index=False)[\"count\"].sum(), \n",
    "                         columns= [\"Tempo\",\"average happy\",\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tempo</th>\n",
       "      <th>average happy</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1556</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tempo  average happy  count\n",
       "0      1         1.1111      2\n",
       "1      1         1.1333      1\n",
       "2      1         1.1556      2\n",
       "3      1         1.1778      2\n",
       "4      1         1.2000      1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotherdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus this table keeps track of each tempo, averahe happy score pair and their individual occurence count, plotting this we see that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(anotherdf, x=\"average happy\", y=\"Tempo\",\n",
    "\t         size=\"count\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting graph:\n",
    "\n",
    "<img src=\"RQ4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The lower the tempo is, the lower the average happy score is. Higher the tempo is, the more spread out the score is across the board. Thus this would imply that a low tempo does imply a non-happy response, but a high tempo does not inherently imply a happy emotional response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Discussion - Limitations and Future Work\n",
    "\n",
    "- Although this data does provide proof in the form of previous research, that a complete factorial stimuli generation is unnecessary, it would be more interesting to have a complete and rich dataset to properly analyze any relationships that may have been missed or could lead to a deeper understanding of how music and emotions are mapped\n",
    "\n",
    "- Mean emotional response is a good descriptor to record, but providing us with each response of the 46 individuals could have let us analyze more things that could have conncted each user / other descriptors could have beem amalyzed such as median or mode to see if these provided different insights\n",
    "\n",
    "- Again although the research is backed by previous research that emotional response is not subjective, it could have been interesting to spread the test users across a more diverse geographic location and included some more demographic information such as age or occupation, to see if any more relationshups could have been mapped.\n",
    "\n",
    "- Also the test situation for each user has not been very clearly outlined in the study (I should imagine if I'm listening to 200 musical stimuli at a stretch, all musical stimuli would begin to sound sad)\n",
    "\n",
    "- For future work it would be interesting to see more in depth analysis of both testers and the stimuli to gain further insight on how emotions are related to melodic stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Conclusions and Reflections\n",
    "\n",
    "It is clear that there are some definite relationships between musical stimuli and emotional response, and further more it is clear that certain characteristics of musical stimuli can be altered to generate or incur a specific emotional response, such an insight can lead to more in deoth understadning of how emotions are mapped in our brains, but could also potentially be a cause for concern if used in unethical situations in illicit a specific response. It feels like such research could steer dabgerously close to topics such a brain washing or hypnosis, which has it's own set of ethical dilemmas and conundrums. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. References\n",
    "\n",
    "- [Happy, sad, scary and peaceful musical excerpts for research on emotions - Veillard et. al](https://www.researchgate.net/publication/247496910_Happy_sad_scary_and_peaceful_musical_excerpts_for_research_on_emotions)\n",
    "- [Emotion rendering in music: range and characteristic values of seven musical variables - Bresin et. al](https://www.ncbi.nlm.nih.gov/pubmed/21696717)\n",
    "-  [Emotional expression in music: contribution, linearity, and additivity of primary musical cues - Eerola et al.](https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00487/full)\n",
    "- [Multidimensional scaling of emotional responses to\n",
    "music: The effect of musical expertise and of the\n",
    "duration of the excerpts - Bigand et al](http://leadserv.u-bourgogne.fr/files/publications/000103-multidimensional-scaling-of-emotional-responses-to-music-the-effect-of-musical-expertise-and-of-the-duration-of-the-excerpts.pdf)\n",
    "\n",
    "(Please Note: References to each cited research has been peppered through out the assignment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
